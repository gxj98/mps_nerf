<!DOCTYPE html>

<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>MPS-NeRF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/font-awesome.min.css">
    <link rel="stylesheet" href="./files/codemirror.min.css">
    <link rel="stylesheet" href="./files/app.css">


</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-20 text-center">
                <br></br>
                <b>MPS-NeRF</b>: Generalizable 3D Human Rendering from Multiview Images<br>
                <small>
                    IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022 <span style="font-size: 18px;">(Conditionally accepted)</span>
                </small>
            </h1>
            <hr style="margin-top:0px">
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
					<li>
                        <a style="font-size: 16px;">
                            Xiangjun Gao
                        </a>
                        <sup>1</sup>
                    </li>
					<li>
                        <a href="https://jlyang.org/" style="font-size: 16px;">
                            Jiaolong Yang
                        </a>
                        <sup>2</sup>
                    </li>
                    <li>
                        <a style="font-size: 16px;">
                            Jongyoo Kim
                        </a>
                        <sup>2</sup>
                    </li>
					<li>
                        <a href="https://pengsida.net/" style="font-size: 16px;">
                            Sida Peng
                        </a>
                        <sup>3</sup>
                    </li>
					<li>
                        <a href="https://www.microsoft.com/en-us/research/people/zliu/" style="font-size: 16px;">
                            Zicheng Liu
                        </a>
                        <sup>4</sup>
                    </li>
                    <li>
                        <a href="http://www.xtong.info/" style="font-size: 16px;">
                            Xin Tong
                        </a>
                        <sup>2</sup>
                    </li><br>
                    <a></a><br>
					<li>
                        <sup>1</sup>
                        <span style="font-size: 15px;">Beijing Institue of Technology</span>
                    </li>
					<li>
                        <sup>2</sup>
                        <span style="font-size: 15px;">Microsoft Research Asia</span>
                    </li>
                    <li>
                        <sup>3</sup>
						<span style="font-size: 15px;">Zhejiang University</span>
                    </li>
					<li>
                        <sup>4</sup>
						<span style="font-size: 15px;">Microsoft Azure AI</span>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="#" onclick="https://arxiv.org/pdf/2203.16875.pdf">
                            <img src="./files/paper.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>

                    <li>
                        <a href="#" onclick="https://arxiv.org/abs/2203.16875">
                            <img src="./files/arxiv.png" height="60px">
                            <h4><strong>ArXiv</strong></h4>
                        </a>
                    </li>

                    <li>
                        <a href="#" onclick="alert('Coming soon');return false;">
                            <img src="./files/github.png" height="60px">
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
			
                <h3>
                    Abstract
                </h3>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    There has been rapid progress recently on 3D human rendering, including novel view synthesis and pose animation, based on the advances of neural radiance fields (NeRF). However, most existing methods focus on person-specific training and their training typically requires multi-view videos. This paper deals with a new challenging task â€“ rendering novel views and novel poses for a person unseen in training, using only multiview still images as input without videos. For this task, we propose a simple yet surprisingly effective method to train a generalizable NeRF with multiview images as conditional input. The key ingredient is a dedicated representation combining a canonical NeRF and a volume deformation scheme. Using a canonical space enables our method to learn shared properties of human and easily generalize to different people. Volume deformation is used to connect the canonical space with input and target images and query image features for radiance and density prediction. We leverage the parametric 3D human model fitted on the input images to derive the deformation, which works quite well in practice when combined with our canonical NeRF. The experiments on both real and synthetic data with the novel view synthesis and pose animation tasks collectively demonstrate the efficacy of our method.
                </p>
				
				<br /></br>
				<a>
                    <video style="width:100%;height:100%;" playsinline autoplay loop preload muted controls>
                        <source src="./files/demo.mp4" type="video/mp4">
                    </video>
                </a>
            </div>
        </div>
 
        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
				<!--
                <h3>
                    Acknowledgements
                </h3>
				-->
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    The website template was adapted from <a href="https://yudeng.github.io/GRAM/">GRAM</a> and <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
            </div>
        </div>


</body>

</html>


